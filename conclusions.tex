\chapter{Fazit}
\label{chap:conclusions}

\section{Zusammenfassung}
Die in Abschnitt~\ref{sec:goals} aufgeführten Ziele wurden erreicht. Auf Basis von maschinellem Lernen wurde ein Verfahren entwickelt und implementiert, das mit Hilfe von Sensordaten eines Fitness-Trackers und eines Smartphones körperliche Aktivitäten erkennt und dabei nicht auf eine feste Ausrichtung der Geräte angewiesen ist. Zur Evaluation wurde ein Experiment mit 10 Teilnehmern durchgeführt.

Der erste Teil der Entwicklung widmete sich der Implementierung einer robusten Aufzeichnungssoftware für das Android-Betriebssystem, die Rohdaten simultan von mehreren Sensoren anfordert und in einem definierten Dateiformat in Form von \textit{Readings} aufzeichnet. Eine weitere entwickelte Software transformiert die \textit{Readings} in mit Hilfe von Unterteilung in Intervalle Instanzen, die als Trainings- und Testdaten für konventionelle ML-Algorithmen dienen, die anschließend eingesetzt werden.

Evaluiert wurden die Genauigkeiten von Modellen, die auf Basis verschiedener ML-Algorithmen und mit Hilfe von Datensätzen verschiedener Sensoren entstanden sind. Die wichtigste Fragestellung dieser Arbeit war, ob die Kombination der Daten eines Smartphones und eines Fitness-Trackers die Genauigkeit der Modelle steigern kann. Insbesondere Abschnitt~\ref{sec:combination-effect} beantwortet diese Frage: Persönliche Modelle, die für jeden Teilnehmer exklusiv mit dessen Daten gebildet wurden, erreichen durch die Kombination der Sensoren eine Genauigkeit von $99.4 \%$ und sind damit $7.8$ Prozentpunkte besser als persönliche Modelle, die lediglich die Daten des Beschleunigungssensors des Fitness-Trackers genutzt haben. Selbst wenn nur die diversen Sensoren des Fitness-Trackers kombiniert werden, kann noch eine Genauigkeit von $97.1 \%$ erzielt werden. Unpersönliche Modelle, die für einen Teilnehmer exklusiv nur die Daten der anderen Teilnehmer verwenden, profitieren ebenfalls von der Datenkombination. Durch diese wird eine Genauigkeit von $78.5 \%$ erreicht, sodass die Genauigkeit der Modelle auf Basis der besten einzelnen Datenquelle, dem Beschleunigungssensor des Fitness-Trackers, um $3.3$ Prozentpunkte übertroffen wird.

Da sich bei der Verwendung unterschiedlicher Sensoren, die in separaten Geräten verbaut sind, die Frage ergibt, inwiefern die Synchronität der \textit{Readings} eine Rolle spielt, wurde der Effekt gaußschen Rauschens auf die Zeitstempel dieser geprüft. Dabei konnte festgestellt werden, dass $\mathcal{N}(0, 500ms)$-verteilte Abweichungen der Zeitstempel der \textit{Readings} keinen nennenswerten Einfluss auf die Genauigkeit haben.

Als weiterer Einfluss auf die Erkennungsrate wurde überprüft, welche Abtastraten für die Aktivitätenerkennung erforderlich sind. Motiviert wurde diese Prüfung dadurch, dass eine höhere Abtastrate zu einem höheren Energieverbrauch führt und die verwendeten Geräte typischerweise keine permanente Stromversorgung haben. In vielen verwandten Arbeiten werden die Sensoren mit 20 Hz abgetastet, jedoch zeigt die Untersuchung, dass für persönliche Modelle sogar eine Abtastrate von 1 Hz ausreichen kann. Unpersönliche Modelle werden von der Reduzierung der Abtastrate stärker geschwächt, jedoch ist mit 5 Hz immer noch eine Genauigkeit von $74.6 \%$ möglich.

Bei der Analyse der Konfusionsmatrizen ist aufgefallen, dass die Ess- und Trinkaktivitäten außergewöhnlich oft untereinander verwechselt werden. Eine Verschmelzung dieser Aktivitäten ermöglichte die Steigerung der Genauigkeit unpersönlicher Modelle um $8.6$ Prozentpunkte auf wesentlich praxistauglichere $87.1 \%$. Hieraus konnte die Erkenntnis abgeleitet werden, dass Aktivitäten für unpersönliche Modelle nicht zu feingranular voneinander abgegrenzt werden sollten.

Hinsichtlich der für die Bildung unpersönlicher Modelle erforderlichen Trainingsdaten konnte in Abschnitt~\ref{sec:accuracy-usercount} festgestellt werden, dass die Kombination unterschiedlicher Sensoren die Notwendigkeit vieler Personen im Datensatz verringern kann. 

Da der von der Transformationssoftware ausgebene Datensatz hochdimensional ist, wurde der Einfluss von Feature-Selection geprüft, dabei jedoch festgestellt, dass dadurch keine Verbesserungen der Genauigkeit möglich waren.

Zusätzlich zu den eigentlichen Zielen dieser Arbeit konnte außerdem herausgefunden werden, dass auch Personen- statt Aktivitätenerkennung hinsichtlich der Erkennungsrate von der Kombination diverser Sensoren profitieren kann.

\section{Beurteilung der Ergebnisse}
Diese Arbeit zeigt, dass die Kombination mehrerer Sensoren zur Gewinnung von \acs{ML}-Modellen konsistent bessere Ergebnisse liefert als die Verwendung einzelner Sensoren. Insbesondere persönliche Modelle profitieren hiervon, da eine fast perfekte Erkennungsrate erreicht wird. Die in dieser Arbeit verwendete Transformationsmethode, die Features aus den \textit{Readings} extrahiert, ist gegenüber der Desynchronisierung der Zeitstempel und unterschiedlichen Ausrichtungen der Geräte resistent, weshalb Anwendern diesbezüglich keine praxisuntauglichen Einschränkungen auferlegt werden müssen. Werden unpersönliche Modelle verwendet, sollte darauf geachtet werden, dass sich die definierten Aktivitäten hinreichend voneinander unterscheiden, da beispielsweise das Auseinanderhalten von Essaktivitäten schwierig ist.

Um die Schwäche unpersönlicher Modelle auszugleichen, könnte eine Anwendung in der Praxis für einen neuen Benutzer zunächst auf ein rein-unpersönliches Modell setzen, das dessen Aktivitäten klassifiziert. Die Anwendung kann den Nutzer um Rückmeldungen bitten, ob die vorhergesagte Klasse korrekt war und mit diesen Daten ein hybrides Modell bauen, das sowohl persönliche als auch unpersönliche Daten verwendet. Laut Weiss et al. wird ein persönliches Modell durch die Rückmeldungen des Benutzers nach einiger Zeit genauer als das hybride Modell, sodass auf dieses umgestiegen werden kann \cite{Weiss2012}, sofern alle klassifizierbaren Aktivitäten des unpersönlichen Modells auch durch das persönliche Modell abgedeckt werden.

\section{Ausblick}
In Zukunft sind insbesondere hinsichtlich der Transformation der Daten Weiterentwicklungen denkbar. Einerseits könnten die Aufnahmen verschiedener Sensoren noch intensiver genutzt werden, indem beispielsweise Korrelationsfeatures zwischen den Komponenten der Sensoren hinzugefügt werden und andererseits könnten die Features für mehrere aufeinanderfolgende Intervalle berechnet und als eine Instanz verwendet werden, um die Sequentialität der Signale besser in den Trainingsdaten wiederzugeben. Aufgrund der höheren Dimensionalität des daraus resultierenden Datensatzes müssten dafür allerdings gegebenenfalls mehr Daten aufgenommen werden.

Des Weiteren könnten verschiedene Intervallgrößen ausprobiert werden, anstatt diese auf 10 Sekunden festzulegen. Auch intelligentere Intervallbildungsmethoden, die Aspekte wie Periodizität in den aufgenommenen Daten erkennen, sind denkbar.

Da es sich bei WEKA um eine Java-basierte Software handelt, könnten sowohl das Training als auch die Klassifizierung mittels eines fertigen Modells auf dem Android-Gerät selbst realisiert werden, da Anwendungen für dieses Betriebssystem ebenfalls in Java geschrieben werden. Im Test an einem stationären Computer war das Training eines \acs{RF}-Modells in der Regel innerhalb weniger Sekunden abgeschlossen, sodass auch mobile Prozessoren in der Lage dazu wären, das Training in kurzer Zeit auszuführen. Dies trifft auch auf die Klassifizierung selbst zu, da diese neben der auch für das Training erforderlichen Transformation der Intervalle lediglich das Durchlaufen einer festen Anzahl von Entscheidungsbäumen erfordert.

Nach der Einreichung dieser Bachelorarbeit wird der aufgenommene Datensatz anonymisiert und auf meiner Webseite (\url{https://cbruegg.com}) zur Verfügung gestellt werden.

\section{Reflexion}
Für die Aufzeichnung der \textit{Readings} wurde der Einfachheit wegen \acs{JSON}-Serialisierung verwendet, die sich jedoch im Laufe der Arbeit als ineffizient herausstellte. Aufgrund der Menge der Messdaten mussten diese zusätzlich mit \acs{GZIP} komprimiert werden, um in kurzer Zeit vom Smartphone auf den Datenspeicher hochgeladen werden zu können. Die Deserialisierung des gesamten Datensatzes, der komprimiert noch eine Größe von 231 MiB hat, dauerte innerhalb der Transformationssoftware bis zu einer Minute und sorgte somit bei Tests dieser Software für Verzögerungen. Stattdessen empfehlenswert wäre im Nachhinein die Verwendung eines binären Dateiformats gewesen.

Als eine gute Entscheidung hingegen hat sich erwiesen, alle Rohdaten unbearbeitet zu speichern und durch eine separate Software zu transformieren, anstatt dies in einem Schritt in der Aufzeichnungssoftware zu tun. So war es möglich, viele Parameter auch nachträglich anzupassen.


% vim: set ft=tex
